{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LAB 7: PHÂN TÍCH DỮ LIỆU DẠNG VĂN BẢN VỚI NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Male Names:  ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "Female Names:  ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping corpora\\names.zip.\n"
     ]
    }
   ],
   "source": [
    "#1. Liệt kê các tên của corpus\n",
    "import nltk\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "print(\"Male Names: \", male_names[:10]) \n",
    "print(\"Female Names: \", female_names[:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopwords in english: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
      "Stopwords in french: ['au', 'aux', 'avec', 'ce', 'ces', 'dans', 'de', 'des', 'du', 'elle']\n",
      "Stopwords in spanish: ['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se']\n",
      "Stopwords in german: ['aber', 'alle', 'allem', 'allen', 'aller', 'alles', 'als', 'also', 'am', 'an']\n",
      "Stopwords in italian: ['ad', 'al', 'allo', 'ai', 'agli', 'all', 'agl', 'alla', 'alle', 'con']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#2. Liệt kê danh sách các stopword bằng các ngôn ngữ khác nhau\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "languages = ['english', 'french', 'spanish', 'german', 'italian']\n",
    "for language in languages:\n",
    "    print(f\"Stopwords in {language}: {stopwords.words(language)[:10]}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total stopwords in english: 198\n",
      "Total stopwords in french: 157\n",
      "Total stopwords in spanish: 313\n",
      "Total stopwords in german: 232\n",
      "Total stopwords in italian: 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#3. Kiểm tra danh sách các stopword bằng các ngôn ngữ khác nhau\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "languages = ['english', 'french', 'spanish', 'german', 'italian']\n",
    "for language in languages:\n",
    "    stop_words = stopwords.words(language)\n",
    "    print(f\"Total stopwords in {language}: {len(stop_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered text: ['example', 'text', 'processing', 'using', 'NLTK', 'remove', 'stopwords', '.']\n"
     ]
    }
   ],
   "source": [
    "#4. Loại bỏ các stopword từ một văn bản đã cho\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"This is an example of text processing using NLTK to remove stopwords.\"\n",
    "tokens = word_tokenize(text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"Filtered text:\", filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens without stopwords: ['another', 'example', 'text', 'demonstrate', 'remove', 'stopwords', '.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#5. Bỏ qua các stopword từ danh sách các stopword\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "text = \"This is another example text to demonstrate how to remove stopwords.\"\n",
    "tokens = word_tokenize(text)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tokens_without_stopwords = [word for word in tokens if word.lower() not in stop_words]\n",
    "print(\"Tokens without stopwords:\", tokens_without_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Definition: a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n",
      "Examples: ['the dog barked all night']\n",
      "Definition: a dull unattractive unpleasant girl or woman\n",
      "Examples: ['she got a reputation as a frump', \"she's a real dog\"]\n",
      "Definition: informal term for a man\n",
      "Examples: ['you lucky dog']\n",
      "Definition: someone who is morally reprehensible\n",
      "Examples: ['you dirty dog']\n",
      "Definition: a smooth-textured sausage of minced beef or pork usually smoked; often served on a bread roll\n",
      "Examples: []\n",
      "Definition: a hinged catch that fits into a notch of a ratchet to move a wheel forward or prevent it from moving backward\n",
      "Examples: []\n",
      "Definition: metal supports for logs in a fireplace\n",
      "Examples: ['the andirons were too hot to touch']\n",
      "Definition: go after with the intent to catch\n",
      "Examples: ['The policeman chased the mugger down the alley', 'the dog chased the rabbit']\n"
     ]
    }
   ],
   "source": [
    "#6. Tìm định nghĩa và ví dụ của một từ đã cho bằng WordNet từ Wikipedia\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn\n",
    "synonyms = wn.synsets(\"dog\")\n",
    "for syn in synonyms:\n",
    "    print(\"Definition:\", syn.definition())\n",
    "    print(\"Examples:\", syn.examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synonyms: {'felicitous', 'glad', 'well-chosen', 'happy'}\n",
      "Antonyms: {'unhappy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#7. Tìm tập hợp các từ đồng nghĩa và trái nghĩa của một từ nào đó\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import wordnet as wn\n",
    "# Tìm từ đồng nghĩa và trái nghĩa của từ \"happy\"\n",
    "synonyms = set()\n",
    "antonyms = set()\n",
    "\n",
    "for syn in wn.synsets(\"happy\"):\n",
    "    for lemma in syn.lemmas():\n",
    "        synonyms.add(lemma.name())\n",
    "        if lemma.antonyms():\n",
    "            antonyms.add(lemma.antonyms()[0].name())\n",
    "\n",
    "print(\"Synonyms:\", synonyms)\n",
    "print(\"Antonyms:\", antonyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Có cái nhìn tổng quan về bộ tag, chi tiết của một tag cụ thể trong bộ tag và chi tiết về một số bộ tag liên quan, sử dụng biểu thức chính quy\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "def show_pos_tags(text):\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    print(\"Tagged words:\", tagged)\n",
    "def detailed_tag_example(text, tag='NN'):\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    print(f\"Words with tag '{tag}':\", [word for word, t in tagged if t == tag])\n",
    "def regex_pos_tags(text):\n",
    "    tagged = pos_tag(word_tokenize(text))\n",
    "    print(\"Nouns identified by regex (NN*):\", [word for word, t in tagged if re.match(r'NN.*', t)])\n",
    "text = \"The quick brown fox jumps over the lazy dog.\"\n",
    "show_pos_tags(text)           \n",
    "detailed_tag_example(text)   \n",
    "regex_pos_tags(text)          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between dog and cat: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "#9. So sánh sự giống nhau của hai danh từ đã cho\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "word1 = wn.synset(\"dog.n.01\")\n",
    "word2 = wn.synset(\"cat.n.01\")\n",
    "similarity = word1.wup_similarity(word2)\n",
    "print(f\"Similarity between dog and cat: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between run and jog: 0.18181818181818182\n"
     ]
    }
   ],
   "source": [
    "#10. So sánh sự giống nhau của hai động từ đã cho\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "verb1 = wn.synset(\"run.v.01\")\n",
    "verb2 = wn.synset(\"jog.v.01\")\n",
    "similarity = verb1.wup_similarity(verb2)\n",
    "print(f\"Similarity between run and jog: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total male names: 2943\n",
      "Total female names: 5001\n",
      "First 10 male names: ['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim']\n",
      "First 10 female names: ['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#11. Tìm số lượng tên nam và nữ trong các tên kho ngữ liệu. In tên 10 nam và nữ đầu tiên.\n",
    "import nltk\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "male_names = names.words('male.txt')\n",
    "female_names = names.words('female.txt')\n",
    "print(\"Total male names:\", len(male_names))\n",
    "print(\"Total female names:\", len(female_names))\n",
    "print(\"First 10 male names:\", male_names[:10])\n",
    "print(\"First 10 female names:\", female_names[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 15 random names with labels:\n",
      "('Dianna', 'female')\n",
      "('Lottie', 'female')\n",
      "('Jethro', 'male')\n",
      "('Carlota', 'female')\n",
      "('Joan', 'female')\n",
      "('Angelica', 'female')\n",
      "('Hebert', 'male')\n",
      "('Christophe', 'male')\n",
      "('Merry', 'male')\n",
      "('Staford', 'male')\n",
      "('Don', 'male')\n",
      "('Andromache', 'female')\n",
      "('Gera', 'female')\n",
      "('Ferdinande', 'female')\n",
      "('Lilith', 'female')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#12. In 15 kết hợp ngẫu nhiên đầu tiên được gắn nhãn nam và được gắn nhãn tên nữ từ kho tên.\n",
    "import nltk\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "import random\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "all_names = male_names + female_names\n",
    "random.shuffle(all_names)\n",
    "print(\"First 15 random names with labels:\")\n",
    "for name in all_names[:15]:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last letter and label pairs: [('r', 'male'), ('n', 'male'), ('y', 'male'), ('e', 'male'), ('t', 'male'), ('t', 'male'), ('y', 'male'), ('l', 'male'), ('l', 'male'), ('m', 'male')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\US\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#13. Trích xuất ký tự cuối cùng của tất cả các tên được gắn nhãn và tạo mảng mới với chữ cái cuối cùng của mỗi tên và nhãn được liên kết.\n",
    "import nltk\n",
    "nltk.download('names')\n",
    "from nltk.corpus import names\n",
    "male_names = [(name, 'male') for name in names.words('male.txt')]\n",
    "female_names = [(name, 'female') for name in names.words('female.txt')]\n",
    "all_names = male_names + female_names\n",
    "last_letter_labels = [(name[-1], label) for name, label in all_names]\n",
    "print(\"Last letter and label pairs:\", last_letter_labels[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
